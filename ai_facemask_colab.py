# -*- coding: utf-8 -*-
"""AI_FaceMask_Colab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FQGmTS9ClqgZnWCFMV-7S3me0D2Vshi0

# Google drive setup
* Uses a google account's google drive to store dataset
* prerequisites : a folder named "AI" in the root directory of drive which will be used for dataset.
"""

from google.colab import drive
import os

drive.mount('/content/drive', force_remount=True)
os.chdir("drive/My Drive/AI")

"""# Loading the dataset - 
* Downloads the face mask dataset to your drive and unzips it using drive REST Api.
* Loads the images and its labels to a pandas dataframe
* Save the dataframe as a  pickle file, which can be subsequently used training the model.
* ref : https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA
"""

"""
Preparing the pickle
"""

from pathlib import Path

import pandas as pd
from google_drive_downloader import GoogleDriveDownloader as gdd
from google.colab import drive
from tqdm import tqdm
from pathlib import Path
import shutil


dirpath = Path('data/dataset')
# cleaing tree
if dirpath.exists() and dirpath.is_dir():
    shutil.rmtree(dirpath)

os.makedirs('data/dataset')
datasetPath = Path('data/dataset/dataset.zip')
gdd.download_file_from_google_drive(file_id='1UDvUL7nuzt3JStnN1KOl_onC5h7q6H9O',dest_path=str(datasetPath),unzip=True)

# https://drive.google.com/file/d/1UDvUL7nuzt3JStnN1KOl_onC5h7q6H9O/view?usp=sharing
# Id for hosted file : 1UDvUL7nuzt3JStnN1KOl_onC5h7q6H9O

datasetPath.unlink()
datasetPath = Path('data/dataset')
clothMaskPath = datasetPath/'with_cloth_mask'
surgicalMaskPath = datasetPath/'with_surgical_mask'
ffp2MaskPath = datasetPath/'with_ffp2_mask'
nonMaskPath = datasetPath/'without_mask'

maskDF = pd.DataFrame()
for imgPath in tqdm(list(nonMaskPath.iterdir()), desc='without_mask'):
    maskDF = maskDF.append({
        'image': str(imgPath),
        'mask': 0
    }, ignore_index=True)

for imgPath in tqdm(list(surgicalMaskPath.iterdir()), desc='with_surgical_mask'):
    maskDF = maskDF.append({
        'image': str(imgPath),
        'mask': 1
    }, ignore_index=True)

for imgPath in tqdm(list(clothMaskPath.iterdir()), desc='with_cloth_mask'):
    maskDF = maskDF.append({
        'image': str(imgPath),
        'mask': 2
    }, ignore_index=True)

for imgPath in tqdm(list(ffp2MaskPath.iterdir()), desc='with_ffp2_mask'):
    maskDF = maskDF.append({
        'image': str(imgPath),
        'mask': 3
    }, ignore_index=True)

print(maskDF)

dfName = 'data/dataset/dataset.pickle'
print(f'Saving Dataframe to: {dfName}')
maskDF.to_pickle(dfName)

"""# Custom dataset class
* Loads the dataset as PIL
* Resizes images to 32x32
* Convert image to tensor -https://discuss.pytorch.org/t/pytorch-pil-to-tensor-and-vice-versa/6312
* Normalizes images to have values in the range of 0-1
"""

"""
The DataSet class
"""

from PIL import Image
import numpy as np
from torch import long, tensor
from torch.utils.data.dataset import Dataset
from torchvision.transforms import Compose, Resize, ToTensor, Normalize


class MaskDetectionDataset(Dataset):
    def __init__(self, dataFrame):
        self.dataFrame = dataFrame
        
        self.transformations = Compose([
            Resize((32, 32)),
            ToTensor(),
            Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.225, 0.225, 0.225]
                )
        ])
    
    def __getitem__(self, key):
        if isinstance(key, slice):
            raise NotImplementedError('slicing is not supported')
        
        row = self.dataFrame.iloc[key]
        image = Image.open(row['image']).convert('RGB')
        return {
          'image': self.transformations(image),
          'mask': tensor([row['mask']], dtype=long),
          'path': row['image']
        }
    
    def __len__(self):
        return len(self.dataFrame.index)

"""# CNN model for face mask detection
* The model takes 3 channels(R,G,B) as input
* The model gives an output of one of 4 classes 
* 0 -> without_mask, 1 -> 'with_mask_surgical', 2 -> 'with_mask_cloth', 3 -> 'with_mask_ffp2'
"""

"""
The CNN model
"""

import torch
import torch.nn.init as init
import torch.nn as nn
from torch import Tensor
from torch.nn import (Conv2d, CrossEntropyLoss, Linear, MaxPool2d, ReLU, Sequential, functional)

class FaceMaskDetectorCNN(nn.Module):
    def __init__(self):
        super(FaceMaskDetectorCNN, self).__init__()
        # Conv Layers : Conv2d
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1) # 32 - 3 + 1 + 2*1 
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1) # 32 - 3 + 1 + 2*1
        #fully Connected: Linear :: features
        # torch.nn.Linear(in_features, out_features, bias=True)
        # in_features – size of each input sample
        # out_features – size of each output sample
        batch_size = 3
        # Simulate a 32 x 32 pixel, rgb "image"
        ip = torch.randn(3, 32, 32)
        print(ip.view(batch_size, -1).size())
        self.fc1 = nn.Linear(8 * 8 * 8, 32)  # 8(out_channel :: prev) &&  8 * 8(computation from the forward max_pool2d * 2 with stride 2) 
        self.fc2 = nn.Linear(32, 4) # final feature labels as 4
    
    def forward(self, x: Tensor):
        """ forward pass 
        The forward() method is the actual network transformation. 
        The forward method is the mapping that maps an input tensor 
        to a prediction output tensor.
        # Convolution Operation
        """
        out = functional.max_pool2d(torch.tanh(self.conv1(x)), 2) # 32 -> 16
        out = functional.relu(out)
        out = functional.max_pool2d(torch.tanh(self.conv2(out)), 2) # 16 -> 8
        out = functional.relu(out)
        # flatten
        out = out.view(-1, 8 * 8 * 8)
        out = torch.tanh(self.fc1(out))
        # fc layer
        out = self.fc2(out)
        return out

face_mask_detector_cnn = FaceMaskDetectorCNN()
print(face_mask_detector_cnn

"""# Summary of Layers"""

"""
Print model summary
"""

from torchsummary import summary
print(summary(face_mask_detector_cnn,input_size=(3,32,32)))

"""# Split validation data
* Loads the pickle file that was saved previously
* Splits dataset into 70/30 split for test,validate
* Create a DataLoader helper function for automatic batching
"""

"""
Some utilities
"""

from pathlib import Path
from typing import Dict, List, Union

import pandas as pd
import torch
import torch.nn.init as init
from sklearn.model_selection import train_test_split
from torch import Tensor
from torch.nn import (Conv2d, CrossEntropyLoss, Linear, MaxPool2d, ReLU, Sequential)
from torch.optim import Adam
from torch.optim.optimizer import Optimizer
from torch.utils.data import DataLoader
import itertools
import matplotlib.pyplot as plt

def plot_cm(cm, classes, normalize=False, title='Visualization of the confusion matrix', cmap=plt.cm.Reds):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('Actual True label')
    plt.xlabel('Predicted label')

def prepare_data(mask_df_path) -> None:
        mask_df = pd.read_pickle(mask_df_path)
        # print the distribution
        print(mask_df['mask'].value_counts())
        train, validate = train_test_split(mask_df, test_size=0.3, random_state=0,
                                           stratify=mask_df['mask'])
        return [
            MaskDetectionDataset(train),
            MaskDetectionDataset(validate),
            CrossEntropyLoss()
            ]

def train_dataloader(train_df) -> DataLoader:
    return DataLoader(train_df, batch_size=32, shuffle=True, num_workers=4)

def val_dataloader(validate_df) -> DataLoader:
    return DataLoader(validate_df, batch_size=32, num_workers=4)   

train_df, validate_df, cross_entropy_loss = prepare_data("data/dataset/dataset.pickle")

"""# Training the model
* For each batch get the images and its labels
* Pass it to the model to get predictions
* compare losses with actual, predicted values
"""

epochs = 20 
learning_rate = 0.001 
retrain = False
"""
Training Step
"""

import warnings
warnings.filterwarnings('ignore')

def train_model():
    optimizer = Adam(face_mask_detector_cnn.parameters(), lr=learning_rate)
    for epoch in range(epochs):
        loss_train = 0.0
        for i, data in enumerate(train_dataloader(train_df), 0):
            inputs, labels = data['image'], data['mask']
            labels = labels.flatten()
            outputs = face_mask_detector_cnn(inputs)
            loss = cross_entropy_loss(outputs, labels)
            optimizer.zero_grad() 
            loss.backward()
            optimizer.step()
            loss_train += loss
        print(f' LOSS :: Training Loss (after epoch {epoch}):', loss_train)

train_model()
print('Model training has finished')

"""# Evaluate the model 
* Run the model to evaluate its accuracy on unseen images using validate dataset
* print model's accuracy, f1, precision, recall scores
"""

"""
Evaluate the model
"""

from numpy import vstack
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix

def evaluate_model():
    predictions, actuals = torch.tensor([]), torch.tensor([])
    for i, data in enumerate(val_dataloader(validate_df)):
        inputs, targets = data['image'], data['mask']
        targets = targets.flatten()
        output = face_mask_detector_cnn(inputs)
        output = torch.argmax(output,axis=1)
        predictions = torch.cat((predictions, output.flatten()), dim=0)
        actuals = torch.cat((actuals, targets), dim=0)  
        
    #print metrics
    classes = ['without_mask','with_mask_surgical', 'with_mask_cloth', 'with_mask_ffp2']
    print(classification_report(actuals, predictions, digits = 4, target_names=classes))
    confusion_mat = confusion_matrix(actuals.numpy(), predictions.numpy())
    plot_cm(confusion_mat, classes)
evaluate_model()

"""# Prediction of random image using trained Model"""

"""
Predict
"""

import matplotlib.pyplot as plt
import random

class_mapping = {
    0: "without_mask",
    1: "with_mask_surgical",
    2: "with_mask_cloth",
    3: "with_mask_ffp2",
}

def predict():
  rand_sampler = torch.utils.data.RandomSampler(validate_df, num_samples=32, replacement=True)
  data = iter(DataLoader(validate_df, batch_size=32, num_workers=1, sampler=rand_sampler)).next()
  inputs,targets = data['image'], data['mask']
  output = face_mask_detector_cnn(inputs)
  output = torch.argmax(output,axis=1)
  rand_ind = random.choice(list(range(0,32)))
  print(data['path'][rand_ind])
  img = Image.open(data['path'][rand_ind])
  plt.imshow(np.asarray(img))
  print("Actual:", class_mapping[targets[rand_ind].tolist()[0]])
  print("Predicted:",class_mapping[output[rand_ind].tolist()])

predict()